{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e658bb7-ff15-4ba9-a2fa-4ad16a40596a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ad9261-69f6-466b-881a-c8b8e24c03ef",
   "metadata": {},
   "source": [
    "# Set-up Rolling Deployment to replace a Deployed Model\n",
    "\n",
    "This notebook demonstrates how to perform a rolling deployment on Vertex AI to replace an existing deployed model with zero downtime. Rolling deployments gradually transition traffic from the old model to the new model while maintaining service availability.\n",
    "\n",
    "See: [Rolling Deployment documentation](https://cloud.google.com/vertex-ai/docs/predictions/rolling-deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eebadc7e-96b0-407a-bfc9-ff1b7915a984",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import google.auth.transport.requests\n",
    "import google.auth\n",
    "from google.cloud import storage\n",
    "import requests\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690cbd84-4733-4af1-8b11-3da2303962af",
   "metadata": {},
   "source": [
    "#### Configure Deployment Parameters\n",
    "\n",
    "Set the project configuration and deployment parameters:\n",
    "- `ENDPOINT_ID`: The endpoint where the model is deployed (from notebook 01)\n",
    "- `MODEL_ID`: ID of the NEW model from the Vertex AI Model Registry that you want to deploy.\n",
    "- `PREVIOUS_DEPLOYED_MODEL`: DeployedModel ID of a model on the endpoint to replace\n",
    "- `MAX_UNAVAILABLE_REPLICAS`: Number of replicas that can be down during rollout (controls deployment risk)\n",
    "- `MAX_SURGE_REPLICAS`: Number of extra replicas to create temporarily (controls deployment speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1c07e4-169f-44ed-930f-087da147b6f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"sandbox-401718\"  # @param {type:\"string\"}\n",
    "LOCATION_ID = \"us-central1\"  # @param {type:\"string\"}\n",
    "endpoint_name = f\"projects/757654702990/locations/us-central1/endpoints/2725107683605610496\" # @param {type:\"string\"}\n",
    "\n",
    "# Rolling Deployment paramaters \n",
    "ENDPOINT_ID = aiplatform.Endpoint(endpoint_name=endpoint_name).name\n",
    "PREVIOUS_DEPLOYED_MODEL = \"8570832776490647552\" # @param {type:\"string\"} (see CLI command below to list)\n",
    "MODEL_ID = \"323587371566104576\" # @param {type:\"string\"} \n",
    "MAX_UNAVAILABLE_REPLICAS = 1 # @param {type:\"integer\"}\n",
    "MAX_SURGE_REPLICAS = 1 # @param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a7fbf01-98c0-4811-967c-08e914b61f2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "4095662121767927808;8570832776490647552\n"
     ]
    }
   ],
   "source": [
    "# # List the DeployedModel ID of a model on the same endpoint\n",
    "# ! gcloud ai endpoints describe {ENDPOINT_ID}  \\\n",
    "#   --project={PROJECT_ID} \\\n",
    "#   --region={LOCATION_ID} \\\n",
    "#   --format=\"value(deployedModels.id)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94936add-9958-4a75-a432-5ac63dc1de7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Credentials\n",
    "\n",
    "# Set up Application Default Credentials (ADC)\n",
    "credentials, project_id = google.auth.default()\n",
    "auth_req = google.auth.transport.requests.Request()\n",
    "credentials.refresh(auth_req)\n",
    "access_token = credentials.token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca4b331c-5b58-488d-8c96-c84c9c3aa1f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# url = f\"https://discoveryengine.googleapis.com/v1alpha/projects/{PROJECT_ID}/locations/global/podcasts\"\n",
    "url = f\"https://{LOCATION_ID}-aiplatform.googleapis.com/v1beta1/projects/{PROJECT_ID}/locations/{LOCATION_ID}/endpoints/{ENDPOINT_ID}:deployModel\"\n",
    "\n",
    "headers = {\n",
    "    'Authorization': 'Bearer ' + access_token,\n",
    "    'Content-Type': 'application/json; charset=utf-8'\n",
    "}\n",
    "\n",
    "request_body = str({\n",
    "  \"deployedModel\": {\n",
    "    \"model\": f\"projects/{PROJECT_ID}/locations/{LOCATION_ID}/models/{MODEL_ID}\",\n",
    "    \"rolloutOptions\": {\n",
    "      \"previousDeployedModel\": f\"{PREVIOUS_DEPLOYED_MODEL}\",\n",
    "      \"maxUnavailableReplicas\": f\"{MAX_UNAVAILABLE_REPLICAS}\",\n",
    "      \"maxSurgeReplicas\": f\"{MAX_SURGE_REPLICAS}\"\n",
    "    }\n",
    "  }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067eaee2-ab8f-417a-bf49-1fcb6446182a",
   "metadata": {},
   "source": [
    "#### Start Deployment vis REST\n",
    "Initiates the rolling deployment via REST API and polls operation status until completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "krk4lg4vide",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started deployment operation: projects/757654702990/locations/us-central1/endpoints/2725107683605610496/operations/8774335697139007488\n",
      "Deployment completed successfully in 282.50 seconds (4.71 minutes)\n",
      "Result: {'@type': 'type.googleapis.com/google.cloud.aiplatform.v1beta1.DeployModelResponse', 'deployedModel': {'id': '5362018041989169152'}}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Make the initial deployModel request\n",
    "response = requests.post(url, headers=headers, data=request_body)\n",
    "response.raise_for_status()\n",
    "\n",
    "operation = response.json()\n",
    "operation_name = operation['name']\n",
    "print(f\"Started deployment operation: {operation_name}\")\n",
    "\n",
    "# Poll the operation until completion\n",
    "while True:\n",
    "    op_url = f\"https://{LOCATION_ID}-aiplatform.googleapis.com/v1/{operation_name}\"\n",
    "    op_response = requests.get(op_url, headers=headers)\n",
    "    op_response.raise_for_status()\n",
    "    op_data = op_response.json()\n",
    "    \n",
    "    if op_data.get('done', False):\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        \n",
    "        # Check if operation succeeded or failed\n",
    "        if 'error' in op_data:\n",
    "            print(f\"Deployment failed after {elapsed_time:.2f} seconds\")\n",
    "            print(f\"Error: {op_data['error']}\")\n",
    "        else:\n",
    "            print(f\"Deployment completed successfully in {elapsed_time:.2f} seconds ({elapsed_time/60:.2f} minutes)\")\n",
    "            print(f\"Result: {op_data.get('response', {})}\")\n",
    "        break\n",
    "    \n",
    "    # Progress\n",
    "    elapsed = time.time() - start_time\n",
    "    time.sleep(10) "
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m117",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m117"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
